{"data":{"site":{"siteMetadata":{"title":"Mingjun Zhou's blog","author":"Mingjun Zhou","sourceUrl":"https://github.com/zhoumingjun/zhoumingjun.github.io/blob/source/","siteUrl":"https://zhoumingjun.github.io","disqusShortname":"zhoumingjun"}},"markdownRemark":{"id":"d38f013d-5976-5c27-8600-db6f9be05016","html":"<h1>unicode nomalization</h1>\n<h2>Canonical and Compatibility Equivalence</h2>\n<p><a href=\"http://www.unicode.org/reports/tr15/#Canon_Compat_Equivalence\">http://www.unicode.org/reports/tr15/#Canon<em>Compat</em>Equivalence</a></p>\n<p><strong>Examples of Canonical Equivalence</strong></p>\n<table>\n<thead>\n<tr>\n<th>Subtype</th>\n<th>Examples</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Combining sequence</td>\n<td>Ç\t↔\tC+◌̧</td>\n</tr>\n<tr>\n<td>Ordering of combining marks</td>\n<td>q+◌̇+◌̣\t↔\tq+◌̣+◌̇</td>\n</tr>\n<tr>\n<td>Hangul &#x26; conjoining jamo</td>\n<td>가\t↔\tᄀ +ᅡ</td>\n</tr>\n<tr>\n<td>Singleton equivalence</td>\n<td>Ω\t↔\tΩ</td>\n</tr>\n</tbody>\n</table>\n<p><strong>Examples of Compatibility Equivalence</strong>       </p>\n<table>\n<thead>\n<tr>\n<th>Subtype</th>\n<th>Examples</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Font variants</td>\n<td>ℌ\t→\tH</td>\n</tr>\n<tr>\n<td>Linebreaking differences</td>\n<td>[NBSP]\t→\t[SPACE]</td>\n</tr>\n<tr>\n<td>Positional variant forms</td>\n<td>ﻉ\t→\t‌ع‌</td>\n</tr>\n<tr>\n<td>Circled variants</td>\n<td>①\t→\t1</td>\n</tr>\n<tr>\n<td>Width variants</td>\n<td>ｶ\t→\tカ</td>\n</tr>\n<tr>\n<td>Rotated variants</td>\n<td>︷\t→\t{</td>\n</tr>\n<tr>\n<td>Superscripts/subscripts</td>\n<td>i⁹\t→\ti9</td>\n</tr>\n<tr>\n<td>Squared characters</td>\n<td>㌀\t→\tアパート</td>\n</tr>\n<tr>\n<td>Fractions</td>\n<td>¼\t→\t1/4</td>\n</tr>\n<tr>\n<td>Other</td>\n<td>ǆ\t→\tdž</td>\n</tr>\n</tbody>\n</table>\n<h2>Normalization Forms</h2>\n<table>\n<thead>\n<tr>\n<th>Form</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Normalization Form D (NFD)</td>\n<td>Canonical Decomposition</td>\n</tr>\n<tr>\n<td>Normalization Form C (NFC)</td>\n<td>Canonical Decomposition,followed by Canonical Composition</td>\n</tr>\n<tr>\n<td>Normalization Form KD (NFKD)</td>\n<td>Compatibility Decomposition</td>\n</tr>\n<tr>\n<td>Normalization Form KC (NFKC)</td>\n<td>Compatibility Decomposition,followed by Canonical Composition</td>\n</tr>\n</tbody>\n</table>\n<h1>unicode charater category</h1>\n<p><a href=\"https://en.wikipedia.org/wiki/Unicode_character_property#General_Category\">https://en.wikipedia.org/wiki/Unicode<em>character</em>property#General_Category</a>\n<a href=\"http://www.fileformat.info/info/unicode/category/index.htm\">http://www.fileformat.info/info/unicode/category/index.htm</a></p>\n<p>Code\tDescription\n[Cc]\tOther, Control\n[Cf]\tOther, Format\n[Cn]\tOther, Not Assigned (no characters in the file have this property)\n[Co]\tOther, Private Use\n[Cs]\tOther, Surrogate\n[LC]\tLetter, Cased\n[Ll]\tLetter, Lowercase\n[Lm]\tLetter, Modifier\n[Lo]\tLetter, Other\n[Lt]\tLetter, Titlecase\n[Lu]\tLetter, Uppercase\n[Mc]\tMark, Spacing Combining\n[Me]\tMark, Enclosing\n[Mn]\tMark, Nonspacing\n[Nd]\tNumber, Decimal Digit\n[Nl]\tNumber, Letter\n[No]\tNumber, Other\n[Pc]\tPunctuation, Connector\n[Pd]\tPunctuation, Dash\n[Pe]\tPunctuation, Close\n[Pf]\tPunctuation, Final quote (may behave like Ps or Pe depending on usage)\n[Pi]\tPunctuation, Initial quote (may behave like Ps or Pe depending on usage)\n[Po]\tPunctuation, Other\n[Ps]\tPunctuation, Open\n[Sc]\tSymbol, Currency\n[Sk]\tSymbol, Modifier\n[Sm]\tSymbol, Math\n[So]\tSymbol, Other\n[Zl]\tSeparator, Line\n[Zp]\tSeparator, Paragraph\n[Zs]\tSeparator, Space</p>\n<h1>python code</h1>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> unicodedata\nall_letters <span class=\"token operator\">=</span> string<span class=\"token punctuation\">.</span>ascii_letters <span class=\"token operator\">+</span> <span class=\"token string\">\" .,;'\"</span>\nn_letters <span class=\"token operator\">=</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>all_letters<span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">unicodeToAscii</span><span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> <span class=\"token string\">''</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>c <span class=\"token keyword\">for</span> c <span class=\"token keyword\">in</span> unicodedata<span class=\"token punctuation\">.</span>normalize<span class=\"token punctuation\">(</span><span class=\"token string\">'NFD'</span><span class=\"token punctuation\">,</span> s<span class=\"token punctuation\">)</span> <span class=\"token keyword\">if</span> unicodedata<span class=\"token punctuation\">.</span>category<span class=\"token punctuation\">(</span>c<span class=\"token punctuation\">)</span> <span class=\"token operator\">!=</span> <span class=\"token string\">'Mn'</span> <span class=\"token operator\">and</span> c <span class=\"token keyword\">in</span> all_letters<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># show case</span>\n<span class=\"token builtin\">str</span> <span class=\"token operator\">=</span> <span class=\"token string\">'Abelló'</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>c <span class=\"token keyword\">for</span> c <span class=\"token keyword\">in</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>c <span class=\"token keyword\">for</span> c <span class=\"token keyword\">in</span> unicodedata<span class=\"token punctuation\">.</span>normalize<span class=\"token punctuation\">(</span><span class=\"token string\">'NFD'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>c <span class=\"token keyword\">for</span> c <span class=\"token keyword\">in</span> unicodedata<span class=\"token punctuation\">.</span>normalize<span class=\"token punctuation\">(</span><span class=\"token string\">'NFD'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">if</span> unicodedata<span class=\"token punctuation\">.</span>category<span class=\"token punctuation\">(</span>c<span class=\"token punctuation\">)</span><span class=\"token operator\">!=</span> <span class=\"token string\">'Mn'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>c <span class=\"token keyword\">for</span> c <span class=\"token keyword\">in</span> unicodedata<span class=\"token punctuation\">.</span>normalize<span class=\"token punctuation\">(</span><span class=\"token string\">'NFD'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">if</span> unicodedata<span class=\"token punctuation\">.</span>category<span class=\"token punctuation\">(</span>c<span class=\"token punctuation\">)</span><span class=\"token operator\">!=</span> <span class=\"token string\">'Mn'</span>  <span class=\"token operator\">and</span> c <span class=\"token keyword\">in</span> all_letters<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># result </span>\n<span class=\"token punctuation\">[</span><span class=\"token string\">'A'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'b'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'e'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'l'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'l'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'ó'</span><span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">[</span><span class=\"token string\">'A'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'b'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'e'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'l'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'l'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'o'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'́'</span><span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">[</span><span class=\"token string\">'A'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'b'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'e'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'l'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'l'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'o'</span><span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">[</span><span class=\"token string\">'A'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'b'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'e'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'l'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'l'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'o'</span><span class=\"token punctuation\">]</span></code></pre></div>","fileAbsolutePath":"/home/zhoumingjun/github.com/zhoumingjun/zhoumingjun.github.io/content/note/unicode/index.md","fields":{"permalink":"/2018/09/06/unicode","category":"note"},"frontmatter":{"title":"Unicode","date":"September 06, 2018"}}},"pageContext":{"permalink":"/2018/09/06/unicode","prev":{"internal":{"content":"\n# introduction\n\n# config\n## enable ssh\n```\ncd boot\ntouch ssh\n```\n## hack config.txt\n\n/boot/config.txt\n\ndtoverlay=dwc2\n\n## hack cmdline.txt\n\n/boot/cmdline.txt\n\nmodules-load=dwc2,g_ether\n\n# network\n\n## set wireless configuration\n\nfind the available wireless ap\n`iw dev wlan0 scan` \n\ncat /etc/wpa_supplicant/wpa_supplicant.conf\n```\nctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev\nupdate_config=1\ncountry=CN\n\nnetwork={\n\tssid=\"BBHome\"\n\tpsk=\"--\"\n}\n\nnetwork={\n\tssid=\"Boxin2.4G_2\"\n\tpsk=\"--\"\n}\n```\n\n## set static address\n\n```\ninterface usb0\nmetric 300\nstatic ip_address=192.168.7.2\nstatic routers=192.168.7.1\nstatic domain_name_servers=192.168.7.1\n\ninterface wlan0\nmetric 200\nstatic ip_address=10.0.0.200/24\nstatic routers=10.0.0.99\nstatic domain_name_servers=10.0.0.99\n\n```\n\n## share network from usb0\n```\nsudo iptables -t nat -A POSTROUTING -o enp4s0 -j MASQUERADE\n```"},"fields":{"fpath":"/note/rpi/","permalink":"/2018/10/15/raspberrypi-zero-w","category":"note"},"frontmatter":{"title":"RaspberryPi zero w","date":"2018-10-15","tags":["rpi"],"desc":null,"slug":null}},"next":{"internal":{"content":"which foo >/dev/null\ncommand -v foo >/dev/null 2>&1\ntype foo >/dev/null 2>&1\nhash foo 2>/dev/null\n\nif [[ -n \"${commands[perlbrew]}\" ]] ; then\n  ...\nfi\n\n\nhttp://hyperpolyglot.org/unix-shells"},"fields":{"fpath":"/note/inside-shell/","permalink":"/2018/08/31/inside-shell","category":"note"},"frontmatter":{"title":"inside shell","date":"2018-08-31","tags":null,"desc":null,"slug":null}}}}