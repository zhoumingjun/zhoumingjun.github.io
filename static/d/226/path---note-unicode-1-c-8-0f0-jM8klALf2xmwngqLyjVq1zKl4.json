{"data":{"site":{"siteMetadata":{"title":"Mingjun Zhou's blog","author":"Mingjun Zhou","sourceUrl":"https://github.com/zhoumingjun/zhoumingjun.github.io/blob/source/","siteUrl":"https://zhoumingjun.github.io","disqusShortname":"zhoumingjun"}},"markdownRemark":{"id":"e8bffc12-caec-5a07-8755-076f59191966 >>> MarkdownRemark","excerpt":"unicode nomalization Canonical and Compatibility Equivalence http://www.unicode.org/reports/tr15/#Canon Compat Equivalence Examples of…","html":"<h1>unicode nomalization</h1>\n<h2>Canonical and Compatibility Equivalence</h2>\n<p><a href=\"http://www.unicode.org/reports/tr15/#Canon_Compat_Equivalence\">http://www.unicode.org/reports/tr15/#Canon<em>Compat</em>Equivalence</a></p>\n<p><strong>Examples of Canonical Equivalence</strong></p>\n<table>\n<thead>\n<tr>\n<th>Subtype</th>\n<th>Examples</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Combining sequence</td>\n<td>Ç\t↔\tC+◌̧</td>\n</tr>\n<tr>\n<td>Ordering of combining marks</td>\n<td>q+◌̇+◌̣\t↔\tq+◌̣+◌̇</td>\n</tr>\n<tr>\n<td>Hangul &#x26; conjoining jamo</td>\n<td>가\t↔\tᄀ +ᅡ</td>\n</tr>\n<tr>\n<td>Singleton equivalence</td>\n<td>Ω\t↔\tΩ</td>\n</tr>\n</tbody>\n</table>\n<p><strong>Examples of Compatibility Equivalence</strong>       </p>\n<table>\n<thead>\n<tr>\n<th>Subtype</th>\n<th>Examples</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Font variants</td>\n<td>ℌ\t→\tH</td>\n</tr>\n<tr>\n<td>Linebreaking differences</td>\n<td>[\nNBSP\n]\n\t→\t\n[\nSPACE\n]</td>\n</tr>\n<tr>\n<td>Positional variant forms</td>\n<td>ﻉ\t→\t‌ع‌</td>\n</tr>\n<tr>\n<td>Circled variants</td>\n<td>①\t→\t1</td>\n</tr>\n<tr>\n<td>Width variants</td>\n<td>ｶ\t→\tカ</td>\n</tr>\n<tr>\n<td>Rotated variants</td>\n<td>︷\t→\t{</td>\n</tr>\n<tr>\n<td>Superscripts/subscripts</td>\n<td>i⁹\t→\ti9</td>\n</tr>\n<tr>\n<td>Squared characters</td>\n<td>㌀\t→\tアパート</td>\n</tr>\n<tr>\n<td>Fractions</td>\n<td>¼\t→\t1/4</td>\n</tr>\n<tr>\n<td>Other</td>\n<td>ǆ\t→\tdž</td>\n</tr>\n</tbody>\n</table>\n<h2>Normalization Forms</h2>\n<table>\n<thead>\n<tr>\n<th>Form</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Normalization Form D (NFD)</td>\n<td>Canonical Decomposition</td>\n</tr>\n<tr>\n<td>Normalization Form C (NFC)</td>\n<td>Canonical Decomposition,followed by Canonical Composition</td>\n</tr>\n<tr>\n<td>Normalization Form KD (NFKD)</td>\n<td>Compatibility Decomposition</td>\n</tr>\n<tr>\n<td>Normalization Form KC (NFKC)</td>\n<td>Compatibility Decomposition,followed by Canonical Composition</td>\n</tr>\n</tbody>\n</table>\n<h1>unicode charater category</h1>\n<p><a href=\"https://en.wikipedia.org/wiki/Unicode_character_property#General_Category\">https://en.wikipedia.org/wiki/Unicode<em>character</em>property#General_Category</a>\n<a href=\"http://www.fileformat.info/info/unicode/category/index.htm\">http://www.fileformat.info/info/unicode/category/index.htm</a></p>\n<p>Code\tDescription\n[Cc]\tOther, Control\n[Cf]\tOther, Format\n[Cn]\tOther, Not Assigned (no characters in the file have this property)\n[Co]\tOther, Private Use\n[Cs]\tOther, Surrogate\n[LC]\tLetter, Cased\n[Ll]\tLetter, Lowercase\n[Lm]\tLetter, Modifier\n[Lo]\tLetter, Other\n[Lt]\tLetter, Titlecase\n[Lu]\tLetter, Uppercase\n[Mc]\tMark, Spacing Combining\n[Me]\tMark, Enclosing\n[Mn]\tMark, Nonspacing\n[Nd]\tNumber, Decimal Digit\n[Nl]\tNumber, Letter\n[No]\tNumber, Other\n[Pc]\tPunctuation, Connector\n[Pd]\tPunctuation, Dash\n[Pe]\tPunctuation, Close\n[Pf]\tPunctuation, Final quote (may behave like Ps or Pe depending on usage)\n[Pi]\tPunctuation, Initial quote (may behave like Ps or Pe depending on usage)\n[Po]\tPunctuation, Other\n[Ps]\tPunctuation, Open\n[Sc]\tSymbol, Currency\n[Sk]\tSymbol, Modifier\n[Sm]\tSymbol, Math\n[So]\tSymbol, Other\n[Zl]\tSeparator, Line\n[Zp]\tSeparator, Paragraph\n[Zs]\tSeparator, Space</p>\n<h1>python code</h1>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> unicodedata\nall_letters <span class=\"token operator\">=</span> string<span class=\"token punctuation\">.</span>ascii_letters <span class=\"token operator\">+</span> <span class=\"token string\">\" .,;'\"</span>\nn_letters <span class=\"token operator\">=</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>all_letters<span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">unicodeToAscii</span><span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> <span class=\"token string\">''</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>c <span class=\"token keyword\">for</span> c <span class=\"token keyword\">in</span> unicodedata<span class=\"token punctuation\">.</span>normalize<span class=\"token punctuation\">(</span><span class=\"token string\">'NFD'</span><span class=\"token punctuation\">,</span> s<span class=\"token punctuation\">)</span> <span class=\"token keyword\">if</span> unicodedata<span class=\"token punctuation\">.</span>category<span class=\"token punctuation\">(</span>c<span class=\"token punctuation\">)</span> <span class=\"token operator\">!=</span> <span class=\"token string\">'Mn'</span> <span class=\"token operator\">and</span> c <span class=\"token keyword\">in</span> all_letters<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># show case</span>\n<span class=\"token builtin\">str</span> <span class=\"token operator\">=</span> <span class=\"token string\">'Abelló'</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>c <span class=\"token keyword\">for</span> c <span class=\"token keyword\">in</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>c <span class=\"token keyword\">for</span> c <span class=\"token keyword\">in</span> unicodedata<span class=\"token punctuation\">.</span>normalize<span class=\"token punctuation\">(</span><span class=\"token string\">'NFD'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>c <span class=\"token keyword\">for</span> c <span class=\"token keyword\">in</span> unicodedata<span class=\"token punctuation\">.</span>normalize<span class=\"token punctuation\">(</span><span class=\"token string\">'NFD'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">if</span> unicodedata<span class=\"token punctuation\">.</span>category<span class=\"token punctuation\">(</span>c<span class=\"token punctuation\">)</span><span class=\"token operator\">!=</span> <span class=\"token string\">'Mn'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>c <span class=\"token keyword\">for</span> c <span class=\"token keyword\">in</span> unicodedata<span class=\"token punctuation\">.</span>normalize<span class=\"token punctuation\">(</span><span class=\"token string\">'NFD'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">if</span> unicodedata<span class=\"token punctuation\">.</span>category<span class=\"token punctuation\">(</span>c<span class=\"token punctuation\">)</span><span class=\"token operator\">!=</span> <span class=\"token string\">'Mn'</span>  <span class=\"token operator\">and</span> c <span class=\"token keyword\">in</span> all_letters<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># result </span>\n<span class=\"token punctuation\">[</span><span class=\"token string\">'A'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'b'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'e'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'l'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'l'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'ó'</span><span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">[</span><span class=\"token string\">'A'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'b'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'e'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'l'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'l'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'o'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'́'</span><span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">[</span><span class=\"token string\">'A'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'b'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'e'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'l'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'l'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'o'</span><span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">[</span><span class=\"token string\">'A'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'b'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'e'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'l'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'l'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'o'</span><span class=\"token punctuation\">]</span></code></pre></div>","fileAbsolutePath":"/home/zhoumingjun/github.com/zhoumingjun/zhoumingjun.github.io/content/note/unicode/index.md","fields":{"slug":"/note/unicode/","category":"note"},"frontmatter":{"title":"Unicode","dateCreated":"September 06, 2018","dateLastModified":null}}},"pageContext":{"slug":"/note/unicode/","prev":null,"next":{"internal":{"content":"---\ntitle: 'inside shell'\ndateCreated: '2018-08-31T17:08:12Z'\n---\nwhich foo >/dev/null\ncommand -v foo >/dev/null 2>&1\ntype foo >/dev/null 2>&1\nhash foo 2>/dev/null\n\nif [[ -n \"${commands[perlbrew]}\" ]] ; then\n  ...\nfi\n\n\nhttp://hyperpolyglot.org/unix-shells"},"fields":{"slug":"/note/inside-shell/","category":"note"},"frontmatter":{"title":"inside shell","dateCreated":"2018-08-31T17:08:12Z","tags":null,"desc":null}}}}